<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Spark Demo</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">
		<link rel="stylesheet" href="css/tooldemo.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h1>Spark Demo</h1>
					<h4>An open-source cluster-computing framework</h4>
					<p>
						<small>Presented by Xingan Wang &amp; Yiming Wang</small>
					</p>
				</section>

				<section>
					<h2>Introduction</h2>
					<section>

						<ul>
							<li>Apache Spark was originally developed at the University of California, Berkeley's AMPLab</li>
							<li>The Spark codebase was later donated to the Apache Software Foundation</li>
							<li>It is a fast and general engine for large-scale data processing</li>
						</ul>
					</section>

					<section>
						<ul>
							<li>"Run programs up to 100x faster than Hadoop MapReduce in memory, or 10x faster on disk."</li>
							<li>DAG Engine (directed acyclic graph) optimizes workflows</li>
						</ul>
					</section>

					<section>
						<ul>
							<li>Code in Python, Java, or Scala</li>
							<li>Built around one main concept: the Resilient Distributed Dataset(RDD).</li>
						</ul>
					</section>

					<section>
						<h3>Why Scala?</h3>
						<ul>
							<li>Spark itself is written in Scala</li>
							<li>Scala uses functional programming model which is a good fit for distributed processing</li>
							<li>Fast performance (python is slow in comparison)</li>
							<li>Scala complies to Java bytecode</li>
						</ul>
					</section>

				</section>

				<section>
					<section>
						<h2>Setup</h2>
					</section>

					<section>
						<h3>Install a Java Development Kit (JDK)</h3>
						<small><a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">JDK Download Site</a></small>
					</section>

					<section>
						<h3>Install Spark</h3>
						<br><small><a href="https://spark.apache.org/downloads.html">Spark Download Site</a></small></br>
						<ul>
							<li>Install Homebrew</li>
							<li>Enter <font color=grey>brew install apache-spark</font></li>
							<li>Create a log4j.properties file via
							   <br><font color=grey>cd /usr/local/Cellar/apache-spark/2.0.0/libexec/conf</font></br>
							   <font color=grey>cp log4j.properties.template log4j.properties</font></li>
							<li>Change the error level from INFO to ERROR for log4j.rootCategory</li>
						</ul>
					</section>

					<section>
						<h3>Install Scala IDE</h3>
						<small><a href="http://scala-ide.org/download/sdk.html">Scala IDE Download Site</a></small>
					</section>
				</section>

				<section>

					<section>
						<h3>Popular Movies</h3>
						<h4>Find the movies with the most ratings.</h4>
					</section>
					<section>
						Main function
						<pre><code class="hljs scala" data-trim contenteditable>
						  def main(args: Array[String]) {

						    // Create a logger to trace the execution
						    // Set the log level to only print errors
						    Logger.getLogger("org").setLevel(Level.ERROR)

						    // Create a SparkContext using EMR's config defaults
						    val conf = new SparkConf().setAppName("PopularMovies")
						    val sc = new SparkContext(conf)

						    // Create a broadcast variable of our ID -> movie name map
						    var nameDict = sc.broadcast(loadMovieNames)

						    ...
						  }
						</code></pre>
					</section>

					<section>
						Build a Map of movie IDs to movie names
						<pre><code class="hljs scala" data-trim contenteditable>
						  def loadMovieNames() : Map[Int, String] = {

						    // Handle character encoding issues:
						    implicit val codec = Codec("UTF-8")
						    codec.onMalformedInput(CodingErrorAction.REPLACE)
						    codec.onUnmappableCharacter(CodingErrorAction.REPLACE)

						    // Create a Map of Ints to Strings.
						    var movieNames:Map[Int, String] = Map()

						    val lines = Source.fromFile("u.item").getLines()
						    for (line &lt;- lines) {
						      var fields = line.split('|')
						      if (fields.length > 1) {
						        movieNames += (fields(0).toInt -> fields(1))
						      }
						    }

						    return movieNames
						  }
						</code></pre>
						<small>u.item: MovieId | MovieName | Date | Link</small>
					</section>

					<section>
						Main function continue
						<pre><code class="hljs scala" data-trim contenteditable>
							...

						    // Read in each rating line
						    val lines = sc.textFile("s3n://xgwang-spark-demo/ml-100k/u.data")

						    // Map to (movieID, 1) tuples
						    val movies = lines.map(x => (x.split("\t")(1).toInt, 1))

						    // Count up all the 1's for each movie
						    val movieCounts = movies.reduceByKey( (x, y) => x + y )

						    // Flip (movieID, count) to (count, movieID)
						    val flipped = movieCounts.map( x => (x._2, x._1) )

						    // Sort
						    val sortedMovies = flipped.sortByKey()

						    // Fold in the movie names from the broadcast variable
						    val sortedMoviesWithNames = sortedMovies.map(x => (nameDict.value(x._2), x._1))

						    // Collect and print results
						    val results = sortedMoviesWithNames.collect()

						    results.foreach(println)
						  }
						</code></pre>
						<small>u.data: UserId, MovieId, Rating, Time.</small>
					</section>

				</section>

				<section>
					<h2>Packaging and Deploying your application</h2>
					<ul>
						<li>Package up your Scala project into a JAR file</li>
						<li>Upload jar files and data files to aws S3</li>
						<li>Login to EMR/EC2 and download jar file and data file</li>
						<li><code>spark-submit</code> to run</li>
					</ul>
				</section>

				<section>
					<h2>Thanks</h2>

				</section>

			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
